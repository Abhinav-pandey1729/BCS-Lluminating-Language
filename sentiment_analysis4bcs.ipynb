{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Load the dataset\ndata = pd.read_csv('IMDB Dataset.csv')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Exploratory Data Analysis (EDA)\nprint(data.head())\nprint(data.info())\nprint(data.describe())\nprint(data['sentiment'].value_counts())\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Drop unnecessary columns\ndata = data[['review', 'sentiment']]\n\n# Pad sequences\nmax_length = 100 \n\n# Set the maximum length of sequences\nX = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')\n\n# Encode sentiment labels\ny = data['sentiment'].values\n\n# Split the data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(data['review'], data['sentiment'], test_size=0.2, random_state=42)\n\n#see the shape of data\nprint (\"The shape of the  data is (row, column):\"+ str(data.shape))\nprint (data.info())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Download required NLTK resources\nnltk.download('stopwords')\nnltk.download('punkt')\n\n# Define a function to preprocess the text\nstop_words = set(stopwords.words('english'))\n\ndef preprocess_text(text):\n    text = text.lower()\n    text = ' '.join([word for word in text.split() if word not in stop_words])\n    return text\n\n# Apply the preprocessing function to the training and test data\nX_train = X_train.apply(preprocess_text)\nX_test = X_test.apply(preprocess_text)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Tokenization\nstemmer = PorterStemmer()\nstop_words = set(stopwords.words('english'))\n\ndef preprocess_text(text):\n    tokens = nltk.word_tokenize(text)\n    tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]\n    return ' '.join(tokens)\n\ndata['review'] = data['review'].apply(preprocess_text)\n\n# Tokenize the text data\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(data['review'])\nsequences = tokenizer.texts_to_sequences(data['review'])\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Train the model\nclf.fit(X_train_vectors, y_train)\n\n# Make predictions on the test set\ny_pred = clf.predict(X_test_vectors)\n\n# Print the classification report\nprint(classification_report(y_test, y_pred))\n\n# Print the confusion matrix\nprint(confusion_matrix(y_test, y_pred))\n\n# Example new review\nnew_review = \"This movie was amazing! I loved the plot and the acting was superb.\"\n\n# Preprocess the new review\nnew_review_processed = preprocess_text(new_review)\n\n# Transform the new review\nnew_review_vector = vectorizer.transform([new_review_processed])\n\n# Make a prediction\nsentiment = clf.predict(new_review_vector)[0]\nprint(\"Predicted Sentiment:\", sentiment)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "\n\n# Define the model\nvocab_size = len(tokenizer.word_index) + 1\nembedding_dim = 100\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "\n# Initialize the TF-IDF vectorizer\nvectorizer = TfidfVectorizer()\n\n# Fit and transform the training data\nX_train_vectors = vectorizer.fit_transform(X_train)\n\n# Transform the test data\nX_test_vectors = vectorizer.transform(X_test)\n\n\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Initialize the Multinomial Naive Bayes classifier\nclf = MultinomialNB()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Compile the model\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Train the model\nepochs = 10\nbatch_size = 32\nmodel.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test))\n\n# Evaluate the model\ny_pred = model.predict(X_test)\ny_pred_classes = [1 if prob > 0.5 else 0 for prob in y_pred]\n\n# Accuracy Score\naccuracy = accuracy_score(y_test, y_pred_classes)\nprint(f'Accuracy Score: {accuracy:.4f}')\n\n# ROC-AUC\nroc_auc = roc_auc_score(y_test, y_pred)\nprint(f'ROC-AUC: {roc_auc:.4f}')\n\n# F1 Score\nf1 = f1_score(y_test, y_pred_classes)\nprint(f'F1 Score: {f1:.4f}')\n\n# Confusion Matrix\nconf_matrix = confusion_matrix(y_test, y_pred_classes)\nprint('Confusion Matrix:')\nprint(conf_matrix)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}